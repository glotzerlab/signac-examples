{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9b0fb3d2-f23f-416d-bc01-7d817ad98cc9"
    }
   },
   "source": [
    "# 1.3. A Basic Workflow\n",
    "\n",
    "This part of the tutorial requires [numpy](http://www.numpy.org).\n",
    "\n",
    "## Operations\n",
    "\n",
    "For this part of the tutorial we will imagine that we are still not convinced of the pressure-volume relations that we just \"discovered\" and that calculating the volume is actually a very expensive procedure, such as a [many particle simulation](http://glotzerlab.engin.umich.edu/hoomd-blue/).\n",
    "\n",
    "We emulate this by adding an optional *cost* argument to our volume calculation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b89db729-97f6-4734-a219-45f7279c60f1"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "def V_idg(N, p, kT, cost=0):\n",
    "    sleep(cost)\n",
    "    return N * kT / p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "254fed93-2d9e-485a-868e-868b8ab119cc"
    }
   },
   "source": [
    "It is useful to think of each modification of the workspace, that includes addition, modification, and removal of data, in terms of an *operation*.\n",
    "\n",
    "**An operation should take only one(!) argument: the job handle.**\n",
    "\n",
    "Any additional arguments may represent hidden state point parameters which would lead to a loss of provenance and possibly render our data space inconsistent.\n",
    "\n",
    "The following function is an example for an operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a8042a93-6932-48d3-ab2e-1b51ab91b759"
    }
   },
   "outputs": [],
   "source": [
    "def compute_volume(job):\n",
    "    print(\"Computing volume of\", job)\n",
    "    V = V_idg(cost=1, **job.statepoint())\n",
    "    job.document[\"V\"] = V\n",
    "    with open(job.fn(\"V.txt\"), \"w\") as file:\n",
    "        file.write(str(V) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation computes the volume solely based on the state point parameters and stores the results such that they are clearly associated with the job, i.e., in the [job document](http://signac.readthedocs.io/en/latest/projects.html#the-job-document) and in a [file](http://signac.readthedocs.io/en/latest/signac.contrib.html#signac.contrib.job.Job.fn) within the job's workspace.\n",
    "\n",
    "*Please note, that the only reason for storing the the same result in two different ways is for demonstration purposes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "To execute our first data space operation, we simply loop through our project's data space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signac\n",
    "\n",
    "project = signac.init_project(\"projects/tutorial\")\n",
    "\n",
    "for job in project:\n",
    "    compute_volume(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66bce051-6aee-4a78-987b-120d55402824"
    }
   },
   "source": [
    "## Data Space Initialization\n",
    "\n",
    "Since our operation is now more expensive, it is a good idea to split initialization and execution.\n",
    "Let's initialize a few more state points in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "08342212-d34f-4763-9d58-d5b78a70bb73"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import signac\n",
    "\n",
    "project = signac.get_project(root=\"projects/tutorial\")\n",
    "\n",
    "\n",
    "def init_statepoints(n):\n",
    "    for p in np.linspace(0.1, 10.0, n):\n",
    "        sp = {\"p\": p, \"kT\": 1.0, \"N\": 1000}\n",
    "        job = project.open_job(sp)\n",
    "        job.init()\n",
    "        print(\"initialize\", job)\n",
    "\n",
    "\n",
    "init_statepoints(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "635ead70-2f3a-4676-ba62-d7d1328d52ad"
    }
   },
   "source": [
    "We see that initializing more jobs and even reinitializing old jobs is no problem.\n",
    "However, since our calculation will be \"expensive\", we would want to skip the computation whenever the result is already available.\n",
    "\n",
    "One possibility is to add a simple check before executing the computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c5b60f8c-5919-48fe-abb9-9140b41b12b8"
    }
   },
   "outputs": [],
   "source": [
    "for job in project:\n",
    "    if \"V\" not in job.document:\n",
    "        compute_volume(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "425cdcfe-046c-4908-8bbe-218f07240fa2"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "It would be even better, if we could get an overview of which state points have been calculated and which not.\n",
    "We call this a project's *status*.\n",
    "\n",
    "Before we continue, let's initialize a few more state points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "6c86712c-93c3-40de-b4e2-8c99fc0ea114"
    }
   },
   "outputs": [],
   "source": [
    "init_statepoints(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "95ef85d2-6d8c-4f9d-a4f6-ddb692c66053"
    }
   },
   "source": [
    "Next, we implement a `classify()` [generator function](http://stackoverflow.com/questions/1756096/understanding-generators-in-python), which labels a *job* based on certain conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c4103f15-9991-4aae-8844-cacfee4a62b0"
    }
   },
   "outputs": [],
   "source": [
    "def classify(job):\n",
    "    yield \"init\"\n",
    "    if \"V\" in job.document and job.isfile(\"V.txt\"):\n",
    "        yield \"volume-computed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d76a4d9c-96f8-4515-a798-4fa2c98e5e96"
    }
   },
   "source": [
    "Our classifier will always yield the `init` label, but the `volume-computed` label is only yielded if the result has been computed and stored both in the *job document* and as a text file.\n",
    "We can then use this function to get an overview of our project's status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "316f0e4c-0f68-433a-a7d8-3b21dfd53b4c"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Status: {}\".format(project))\n",
    "for job in project:\n",
    "    labels = \", \".join(classify(job))\n",
    "    p = round(job.sp.p, 1)\n",
    "    print(job, p, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fd2269a9-b11e-45a5-837b-ee8aa81c47c8"
    }
   },
   "source": [
    "Using only simple classification functions, we already get a very good grasp on our project's overall status.\n",
    "\n",
    "Furthermore, we can use the classification labels for controling the execution of operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e393ff4c-e0b9-47f4-81f5-edd5732bb63a"
    }
   },
   "outputs": [],
   "source": [
    "for job in project:\n",
    "    labels = classify(job)\n",
    "    if \"volume-computed\" not in labels:\n",
    "        compute_volume(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization\n",
    "\n",
    "So far, we have executed all *operations* in serial using a simple for-loop.\n",
    "We will now learn how to easily **parallelize** the execution!\n",
    "\n",
    "Instead of using a `for-loop`, we can also take advantage of Python's built-in [map-operator](https://docs.python.org/3/library/functions.html#map):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(map(compute_volume, project))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `map()` expression makes it trivial to implement parallelization patterns, for example, using a process [Pool](https://docs.python.org/3.6/library/multiprocessing.html#multiprocessing.pool.Pool):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "with Pool() as pool:\n",
    "    pool.map(compute_volume, list(project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a `ThreadPool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "with ThreadPool() as pool:\n",
    "    pool.map(compute_volume, list(project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cedcb2a4-7e91-4457-bb2b-fc581f039218"
    }
   },
   "source": [
    "Uncomment and execute the following line if you want to remove all data and start over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "471ffb2a-a5f8-4e1c-9ebe-1f2007896a0b"
    }
   },
   "outputs": [],
   "source": [
    "# %rm -r projects/tutorial/workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we learned how to create a simple, yet complete workflow for our computational investigation.\n",
    "\n",
    "In the [next section](signac_104_Modifying_the_Data_Space.ipynb) we will learn how to adjust the data space, e.g., modify existing state point parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
